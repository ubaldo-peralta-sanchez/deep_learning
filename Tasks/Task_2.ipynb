{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your first NN (20%)\n",
    "\n",
    "- Efectuar una red neuronal sobre un dataset propio a poder ser siguiendo cualquiera de los tutoriales de la documentación de Tensorflow. El objetivo del ejercicio es poner en práctica el concepto de \"prototipado rápido\" y cruzar la línea para empezar a trabajar en un problema real.\n",
    "- El problema a tratar es uno y sólo uno. Se adjuntan 3 tutoriales y se pide seguir como modelo únicamente el que se elija.\n",
    "- Al ser datos propios, no es necesario adjuntarlos con la entrega.\n",
    "- Si usas datos sensibles, además de no adjuntarlos en el zip, asegúrate de que no se vean en ninguna celda (por ejemplo en celdas de tipo df.head())\n",
    "- El ejercicio vale 2 puntos.\n",
    "- No se evalúa la calidad del modelo, sino la documentación que se hace  y las posibles conclusiones que en pocas líneas se puedan sacar.\n",
    "- Se requiere probar 3 arquitecturas.\n",
    "- Se requiere una búsqueda de hiperparámetros.\n",
    "- De no disponer de datos propios, se puede usar cualquier otro datset. Encontraréis una sugerencia sin embargo como \"Juguete\".\n",
    "\n",
    "### Regression\n",
    "https://www.tensorflow.org/tutorials/keras/regression\n",
    "\n",
    "Juguete: https://www.kaggle.com/gregorut/videogamesales\n",
    "\n",
    "### Classificartion\n",
    "https://www.tensorflow.org/tutorials/structured_data/imbalanced_data\n",
    "\n",
    "Juguete: https://www.kaggle.com/bobbyscience/league-of-legends-diamond-ranked-games-10-min\n",
    "\n",
    "### Time series\n",
    "https://www.tensorflow.org/tutorials/structured_data/time_series\n",
    "\n",
    "Juguete: https://www.kaggle.com/kinguistics/starcraft-scouting-the-enemy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from numpy import loadtxt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cargamos el dataset de league of legends\n",
    "lol = loadtxt('data/high_diamond_ranked_10min.csv',delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into input (X) and output (y) variables\n",
    "X = lol[:,2:]\n",
    "y = lol[:,1].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.1000e+01,  4.0000e+00,  1.0000e+00, ..., -2.9100e+03,\n",
       "         2.2600e+01,  1.5952e+03],\n",
       "       [ 1.4000e+01,  3.0000e+00,  0.0000e+00, ..., -1.0590e+03,\n",
       "         1.8800e+01,  1.7140e+03],\n",
       "       [ 1.7000e+01,  3.0000e+00,  0.0000e+00, ...,  2.2770e+03,\n",
       "         2.6000e+01,  1.9022e+03],\n",
       "       ...,\n",
       "       [ 1.3000e+01,  0.0000e+00,  0.0000e+00, ...,  1.0080e+03,\n",
       "         2.3300e+01,  1.6002e+03],\n",
       "       [ 1.3000e+01,  0.0000e+00,  0.0000e+00, ...,  5.3640e+03,\n",
       "         2.1800e+01,  1.9447e+03],\n",
       "       [ 1.3000e+01,  1.0000e+00,  0.0000e+00, ...,  1.5920e+03,\n",
       "         2.5000e+01,  1.7065e+03]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# demonstrate that the train-test split procedure is repeatable\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# split into train test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arquitectura 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "232/232 [==============================] - 0s 451us/step - loss: 108.1254 - accuracy: 0.6249\n",
      "Epoch 2/100\n",
      "232/232 [==============================] - 0s 438us/step - loss: 30.8190 - accuracy: 0.6313\n",
      "Epoch 3/100\n",
      "232/232 [==============================] - 0s 442us/step - loss: 27.3858 - accuracy: 0.6526\n",
      "Epoch 4/100\n",
      "232/232 [==============================] - 0s 438us/step - loss: 29.0623 - accuracy: 0.6410\n",
      "Epoch 5/100\n",
      "232/232 [==============================] - 0s 446us/step - loss: 31.2887 - accuracy: 0.6351\n",
      "Epoch 6/100\n",
      "232/232 [==============================] - 0s 442us/step - loss: 25.8641 - accuracy: 0.6403\n",
      "Epoch 7/100\n",
      "232/232 [==============================] - 0s 455us/step - loss: 25.8949 - accuracy: 0.6290\n",
      "Epoch 8/100\n",
      "232/232 [==============================] - 0s 464us/step - loss: 24.9200 - accuracy: 0.6458\n",
      "Epoch 9/100\n",
      "232/232 [==============================] - 0s 451us/step - loss: 26.8062 - accuracy: 0.6454\n",
      "Epoch 10/100\n",
      "232/232 [==============================] - 0s 442us/step - loss: 25.4442 - accuracy: 0.6474\n",
      "Epoch 11/100\n",
      "232/232 [==============================] - 0s 443us/step - loss: 21.4575 - accuracy: 0.6425\n",
      "Epoch 12/100\n",
      "232/232 [==============================] - 0s 446us/step - loss: 23.1142 - accuracy: 0.6473\n",
      "Epoch 13/100\n",
      "232/232 [==============================] - 0s 445us/step - loss: 22.7946 - accuracy: 0.6642\n",
      "Epoch 14/100\n",
      "232/232 [==============================] - 0s 437us/step - loss: 21.1600 - accuracy: 0.6555\n",
      "Epoch 15/100\n",
      "232/232 [==============================] - 0s 442us/step - loss: 23.7859 - accuracy: 0.6548\n",
      "Epoch 16/100\n",
      "232/232 [==============================] - 0s 438us/step - loss: 21.9844 - accuracy: 0.6564\n",
      "Epoch 17/100\n",
      "232/232 [==============================] - 0s 438us/step - loss: 19.4693 - accuracy: 0.6405\n",
      "Epoch 18/100\n",
      "232/232 [==============================] - 0s 442us/step - loss: 30.2673 - accuracy: 0.6325\n",
      "Epoch 19/100\n",
      "232/232 [==============================] - 0s 446us/step - loss: 23.9039 - accuracy: 0.6269\n",
      "Epoch 20/100\n",
      "232/232 [==============================] - 0s 446us/step - loss: 18.1291 - accuracy: 0.6595\n",
      "Epoch 21/100\n",
      "232/232 [==============================] - 0s 459us/step - loss: 26.4428 - accuracy: 0.6313\n",
      "Epoch 22/100\n",
      "232/232 [==============================] - 0s 451us/step - loss: 29.9733 - accuracy: 0.6344\n",
      "Epoch 23/100\n",
      "232/232 [==============================] - 0s 442us/step - loss: 21.9543 - accuracy: 0.6425\n",
      "Epoch 24/100\n",
      "232/232 [==============================] - 0s 446us/step - loss: 17.4854 - accuracy: 0.6317\n",
      "Epoch 25/100\n",
      "232/232 [==============================] - 0s 451us/step - loss: 30.0565 - accuracy: 0.6375\n",
      "Epoch 26/100\n",
      "232/232 [==============================] - 0s 442us/step - loss: 21.7006 - accuracy: 0.6470\n",
      "Epoch 27/100\n",
      "232/232 [==============================] - 0s 455us/step - loss: 26.1148 - accuracy: 0.6452\n",
      "Epoch 28/100\n",
      "232/232 [==============================] - 0s 472us/step - loss: 20.8323 - accuracy: 0.6393\n",
      "Epoch 29/100\n",
      "232/232 [==============================] - 0s 455us/step - loss: 16.2123 - accuracy: 0.6289\n",
      "Epoch 30/100\n",
      "232/232 [==============================] - 0s 451us/step - loss: 23.1284 - accuracy: 0.6472\n",
      "Epoch 31/100\n",
      "232/232 [==============================] - 0s 446us/step - loss: 17.1948 - accuracy: 0.6428\n",
      "Epoch 32/100\n",
      "232/232 [==============================] - 0s 451us/step - loss: 15.0393 - accuracy: 0.6407\n",
      "Epoch 33/100\n",
      "232/232 [==============================] - 0s 459us/step - loss: 15.3545 - accuracy: 0.6363\n",
      "Epoch 34/100\n",
      "232/232 [==============================] - 0s 455us/step - loss: 17.6998 - accuracy: 0.6379\n",
      "Epoch 35/100\n",
      "232/232 [==============================] - 0s 446us/step - loss: 17.9593 - accuracy: 0.6428\n",
      "Epoch 36/100\n",
      "232/232 [==============================] - 0s 438us/step - loss: 15.3331 - accuracy: 0.6499\n",
      "Epoch 37/100\n",
      "232/232 [==============================] - 0s 446us/step - loss: 13.6640 - accuracy: 0.6400\n",
      "Epoch 38/100\n",
      "232/232 [==============================] - 0s 433us/step - loss: 19.8524 - accuracy: 0.6360\n",
      "Epoch 39/100\n",
      "232/232 [==============================] - 0s 446us/step - loss: 25.3091 - accuracy: 0.6460\n",
      "Epoch 40/100\n",
      "232/232 [==============================] - 0s 447us/step - loss: 14.0529 - accuracy: 0.6584\n",
      "Epoch 41/100\n",
      "232/232 [==============================] - 0s 438us/step - loss: 13.9189 - accuracy: 0.6596\n",
      "Epoch 42/100\n",
      "232/232 [==============================] - 0s 442us/step - loss: 15.8695 - accuracy: 0.6399\n",
      "Epoch 43/100\n",
      "232/232 [==============================] - 0s 438us/step - loss: 13.3973 - accuracy: 0.6498\n",
      "Epoch 44/100\n",
      "232/232 [==============================] - 0s 446us/step - loss: 11.4014 - accuracy: 0.6445\n",
      "Epoch 45/100\n",
      "232/232 [==============================] - 0s 446us/step - loss: 12.4923 - accuracy: 0.6417\n",
      "Epoch 46/100\n",
      "232/232 [==============================] - 0s 451us/step - loss: 15.2781 - accuracy: 0.6379\n",
      "Epoch 47/100\n",
      "232/232 [==============================] - 0s 451us/step - loss: 11.4421 - accuracy: 0.6485\n",
      "Epoch 48/100\n",
      "232/232 [==============================] - 0s 451us/step - loss: 13.1360 - accuracy: 0.6440\n",
      "Epoch 49/100\n",
      "232/232 [==============================] - 0s 442us/step - loss: 15.7823 - accuracy: 0.6276\n",
      "Epoch 50/100\n",
      "232/232 [==============================] - 0s 446us/step - loss: 11.9583 - accuracy: 0.6534\n",
      "Epoch 51/100\n",
      "232/232 [==============================] - 0s 438us/step - loss: 11.7755 - accuracy: 0.6420\n",
      "Epoch 52/100\n",
      "232/232 [==============================] - 0s 464us/step - loss: 15.4487 - accuracy: 0.6375\n",
      "Epoch 53/100\n",
      "232/232 [==============================] - 0s 446us/step - loss: 10.8544 - accuracy: 0.6446\n",
      "Epoch 54/100\n",
      "232/232 [==============================] - 0s 446us/step - loss: 11.6838 - accuracy: 0.6544\n",
      "Epoch 55/100\n",
      "232/232 [==============================] - 0s 451us/step - loss: 13.7401 - accuracy: 0.6343\n",
      "Epoch 56/100\n",
      "232/232 [==============================] - 0s 451us/step - loss: 11.5624 - accuracy: 0.6487\n",
      "Epoch 57/100\n",
      "232/232 [==============================] - 0s 442us/step - loss: 18.8823 - accuracy: 0.6374\n",
      "Epoch 58/100\n",
      "232/232 [==============================] - 0s 446us/step - loss: 11.8537 - accuracy: 0.6494\n",
      "Epoch 59/100\n",
      "232/232 [==============================] - 0s 451us/step - loss: 13.6319 - accuracy: 0.6399\n",
      "Epoch 60/100\n",
      "232/232 [==============================] - 0s 442us/step - loss: 10.1834 - accuracy: 0.6406\n",
      "Epoch 61/100\n",
      "232/232 [==============================] - 0s 446us/step - loss: 9.1294 - accuracy: 0.6468\n",
      "Epoch 62/100\n",
      "232/232 [==============================] - 0s 451us/step - loss: 10.2829 - accuracy: 0.6589\n",
      "Epoch 63/100\n",
      "232/232 [==============================] - 0s 451us/step - loss: 8.4860 - accuracy: 0.6507\n",
      "Epoch 64/100\n",
      "232/232 [==============================] - 0s 464us/step - loss: 10.7462 - accuracy: 0.6396\n",
      "Epoch 65/100\n",
      "232/232 [==============================] - 0s 446us/step - loss: 12.2593 - accuracy: 0.6423\n",
      "Epoch 66/100\n",
      "232/232 [==============================] - 0s 455us/step - loss: 10.4566 - accuracy: 0.6346\n",
      "Epoch 67/100\n",
      "232/232 [==============================] - 0s 451us/step - loss: 8.7279 - accuracy: 0.6465\n",
      "Epoch 68/100\n",
      "232/232 [==============================] - 0s 455us/step - loss: 12.3261 - accuracy: 0.6468\n",
      "Epoch 69/100\n",
      "232/232 [==============================] - 0s 442us/step - loss: 9.6513 - accuracy: 0.6449\n",
      "Epoch 70/100\n",
      "232/232 [==============================] - 0s 451us/step - loss: 6.5917 - accuracy: 0.6571\n",
      "Epoch 71/100\n",
      "232/232 [==============================] - 0s 451us/step - loss: 12.9715 - accuracy: 0.6435\n",
      "Epoch 72/100\n",
      "232/232 [==============================] - 0s 459us/step - loss: 6.9224 - accuracy: 0.6442\n",
      "Epoch 73/100\n",
      "232/232 [==============================] - 0s 451us/step - loss: 6.8232 - accuracy: 0.6485\n",
      "Epoch 74/100\n",
      "232/232 [==============================] - 0s 455us/step - loss: 8.6374 - accuracy: 0.6392\n",
      "Epoch 75/100\n",
      "232/232 [==============================] - 0s 446us/step - loss: 10.1104 - accuracy: 0.6446\n",
      "Epoch 76/100\n",
      "232/232 [==============================] - 0s 455us/step - loss: 8.0262 - accuracy: 0.6404\n",
      "Epoch 77/100\n",
      "232/232 [==============================] - 0s 451us/step - loss: 10.0151 - accuracy: 0.6440\n",
      "Epoch 78/100\n",
      "232/232 [==============================] - 0s 451us/step - loss: 8.5513 - accuracy: 0.6287\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "232/232 [==============================] - 0s 459us/step - loss: 7.1911 - accuracy: 0.6361\n",
      "Epoch 80/100\n",
      "232/232 [==============================] - 0s 451us/step - loss: 8.4783 - accuracy: 0.6424\n",
      "Epoch 81/100\n",
      "232/232 [==============================] - 0s 451us/step - loss: 9.6248 - accuracy: 0.6476\n",
      "Epoch 82/100\n",
      "232/232 [==============================] - 0s 442us/step - loss: 7.4993 - accuracy: 0.6460\n",
      "Epoch 83/100\n",
      "232/232 [==============================] - 0s 442us/step - loss: 5.4898 - accuracy: 0.6623\n",
      "Epoch 84/100\n",
      "232/232 [==============================] - 0s 451us/step - loss: 8.8452 - accuracy: 0.6456\n",
      "Epoch 85/100\n",
      "232/232 [==============================] - 0s 455us/step - loss: 7.1107 - accuracy: 0.6512\n",
      "Epoch 86/100\n",
      "232/232 [==============================] - 0s 446us/step - loss: 6.6118 - accuracy: 0.6389\n",
      "Epoch 87/100\n",
      "232/232 [==============================] - 0s 446us/step - loss: 4.6127 - accuracy: 0.6281\n",
      "Epoch 88/100\n",
      "232/232 [==============================] - 0s 446us/step - loss: 5.0119 - accuracy: 0.6394\n",
      "Epoch 89/100\n",
      "232/232 [==============================] - 0s 451us/step - loss: 5.5744 - accuracy: 0.6540\n",
      "Epoch 90/100\n",
      "232/232 [==============================] - 0s 459us/step - loss: 5.8278 - accuracy: 0.6366\n",
      "Epoch 91/100\n",
      "232/232 [==============================] - 0s 472us/step - loss: 6.7507 - accuracy: 0.6391\n",
      "Epoch 92/100\n",
      "232/232 [==============================] - 0s 451us/step - loss: 8.6584 - accuracy: 0.6437\n",
      "Epoch 93/100\n",
      "232/232 [==============================] - 0s 442us/step - loss: 6.2574 - accuracy: 0.6546\n",
      "Epoch 94/100\n",
      "232/232 [==============================] - 0s 446us/step - loss: 8.6127 - accuracy: 0.6471\n",
      "Epoch 95/100\n",
      "232/232 [==============================] - 0s 468us/step - loss: 5.0689 - accuracy: 0.6584\n",
      "Epoch 96/100\n",
      "232/232 [==============================] - 0s 442us/step - loss: 5.7972 - accuracy: 0.6437\n",
      "Epoch 97/100\n",
      "232/232 [==============================] - 0s 446us/step - loss: 6.5382 - accuracy: 0.6507\n",
      "Epoch 98/100\n",
      "232/232 [==============================] - 0s 446us/step - loss: 6.1677 - accuracy: 0.6672\n",
      "Epoch 99/100\n",
      "232/232 [==============================] - 0s 442us/step - loss: 7.1677 - accuracy: 0.6350\n",
      "Epoch 100/100\n",
      "232/232 [==============================] - 0s 446us/step - loss: 6.0786 - accuracy: 0.6437\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_6 (Flatten)          (None, 38)                0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 128)               4992      \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 2)                 258       \n",
      "=================================================================\n",
      "Total params: 5,250\n",
      "Trainable params: 5,250\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# generamos para empezar una arquitectura sencilla\n",
    "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(), \n",
    "                                    tf.keras.layers.Dense(128, activation=tf.nn.relu), \n",
    "                                    tf.keras.layers.Dense(2, activation=tf.nn.softmax)])\n",
    "\n",
    "model.compile(optimizer = tf.optimizers.Adam(),\n",
    "              loss = 'sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# entrenamos el modelo con 100 épocas\n",
    "model.fit(X_train, y_train, epochs=100)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.7025\n",
      "Test Accuracy:  0.7259\n"
     ]
    }
   ],
   "source": [
    "# evaluamos la calidad del modelo\n",
    "train_loss, train_accuracy = model.evaluate(X_train, y_train, verbose = False)\n",
    "print(\"Train Accuracy: {:.4f}\".format(train_accuracy))\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose = False)\n",
    "print(\"Test Accuracy:  {:.4f}\".format(test_accuracy))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arquitectura 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 307.3885 - accuracy: 0.6272\n",
      "Epoch 2/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 21.7360 - accuracy: 0.6280\n",
      "Epoch 3/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 6.2153 - accuracy: 0.6284\n",
      "Epoch 4/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 2.4657 - accuracy: 0.6557\n",
      "Epoch 5/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.9166 - accuracy: 0.6610\n",
      "Epoch 6/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.6559 - accuracy: 0.6645\n",
      "Epoch 7/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 1.0170 - accuracy: 0.6482\n",
      "Epoch 8/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 1.5055 - accuracy: 0.6254\n",
      "Epoch 9/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 1.5346 - accuracy: 0.6556\n",
      "Epoch 10/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.5640 - accuracy: 0.7070\n",
      "Epoch 11/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.5544 - accuracy: 0.7126\n",
      "Epoch 12/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.5936 - accuracy: 0.7077\n",
      "Epoch 13/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.5913 - accuracy: 0.7059\n",
      "Epoch 14/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.6210 - accuracy: 0.7099\n",
      "Epoch 15/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.6152 - accuracy: 0.6746\n",
      "Epoch 16/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.5995 - accuracy: 0.6907\n",
      "Epoch 17/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 2.0294 - accuracy: 0.6167\n",
      "Epoch 18/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.6962 - accuracy: 0.5026\n",
      "Epoch 19/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.6929 - accuracy: 0.4958\n",
      "Epoch 20/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.6928 - accuracy: 0.4952\n",
      "Epoch 21/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.6923 - accuracy: 0.5063\n",
      "Epoch 22/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.6927 - accuracy: 0.5098\n",
      "Epoch 23/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.6925 - accuracy: 0.4973\n",
      "Epoch 24/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.6929 - accuracy: 0.4977\n",
      "Epoch 25/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.6925 - accuracy: 0.4893\n",
      "Epoch 26/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.6928 - accuracy: 0.4989\n",
      "Epoch 27/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.6927 - accuracy: 0.5084\n",
      "Epoch 28/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.6926 - accuracy: 0.4881\n",
      "Epoch 29/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.6926 - accuracy: 0.4900\n",
      "Epoch 30/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.6929 - accuracy: 0.4929\n",
      "Epoch 31/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.6923 - accuracy: 0.5128\n",
      "Epoch 32/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.6926 - accuracy: 0.4914\n",
      "Epoch 33/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.6924 - accuracy: 0.5107\n",
      "Epoch 34/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.6928 - accuracy: 0.4876\n",
      "Epoch 35/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.6928 - accuracy: 0.4991\n",
      "Epoch 36/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.6925 - accuracy: 0.4982\n",
      "Epoch 37/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.6928 - accuracy: 0.5061\n",
      "Epoch 38/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.6925 - accuracy: 0.4985\n",
      "Epoch 39/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.6928 - accuracy: 0.4937\n",
      "Epoch 40/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.6925 - accuracy: 0.5039\n",
      "Epoch 41/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.6926 - accuracy: 0.4883\n",
      "Epoch 42/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.6926 - accuracy: 0.4999\n",
      "Epoch 43/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.6927 - accuracy: 0.5135\n",
      "Epoch 44/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.6925 - accuracy: 0.4927\n",
      "Epoch 45/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.6930 - accuracy: 0.5028\n",
      "Epoch 46/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.6923 - accuracy: 0.5154\n",
      "Epoch 47/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.6930 - accuracy: 0.4931\n",
      "Epoch 48/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.6927 - accuracy: 0.4952\n",
      "Epoch 49/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.6928 - accuracy: 0.5059\n",
      "Epoch 50/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.6928 - accuracy: 0.4985\n",
      "Epoch 51/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.6929 - accuracy: 0.4937\n",
      "Epoch 52/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.6928 - accuracy: 0.4970\n",
      "Epoch 53/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.6924 - accuracy: 0.5026\n",
      "Epoch 54/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.6928 - accuracy: 0.5171\n",
      "Epoch 55/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.6927 - accuracy: 0.4929\n",
      "Epoch 56/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.6923 - accuracy: 0.4986\n",
      "Epoch 57/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.6928 - accuracy: 0.4933\n",
      "Epoch 58/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.6924 - accuracy: 0.5012\n",
      "Epoch 59/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.6925 - accuracy: 0.5043\n",
      "Epoch 60/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.6930 - accuracy: 0.4968\n",
      "Epoch 61/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.6928 - accuracy: 0.5017\n",
      "Epoch 62/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.6925 - accuracy: 0.4913\n",
      "Epoch 63/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.6929 - accuracy: 0.4894\n",
      "Epoch 64/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.6927 - accuracy: 0.4999\n",
      "Epoch 65/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.6929 - accuracy: 0.4972\n",
      "Epoch 66/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.6922 - accuracy: 0.4881\n",
      "Epoch 67/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.6925 - accuracy: 0.5063\n",
      "Epoch 68/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.6925 - accuracy: 0.5073\n",
      "Epoch 69/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.6925 - accuracy: 0.5039\n",
      "Epoch 70/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.6925 - accuracy: 0.4997\n",
      "Epoch 71/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.6926 - accuracy: 0.5063\n",
      "Epoch 72/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.6928 - accuracy: 0.5000\n",
      "Epoch 73/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.6924 - accuracy: 0.5048\n",
      "Epoch 74/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.6929 - accuracy: 0.4977\n",
      "Epoch 75/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.6927 - accuracy: 0.5061\n",
      "Epoch 76/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.6930 - accuracy: 0.4959\n",
      "Epoch 77/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.6926 - accuracy: 0.5003\n",
      "Epoch 78/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.6925 - accuracy: 0.4999\n",
      "Epoch 79/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.6921 - accuracy: 0.5065\n",
      "Epoch 80/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.6928 - accuracy: 0.4969\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "232/232 [==============================] - 1s 3ms/step - loss: 0.6928 - accuracy: 0.5007\n",
      "Epoch 82/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.6929 - accuracy: 0.4964\n",
      "Epoch 83/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.6928 - accuracy: 0.4885\n",
      "Epoch 84/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.6928 - accuracy: 0.5119\n",
      "Epoch 85/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.6929 - accuracy: 0.4887\n",
      "Epoch 86/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.6930 - accuracy: 0.5020\n",
      "Epoch 87/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.6930 - accuracy: 0.4864\n",
      "Epoch 88/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.6923 - accuracy: 0.5132\n",
      "Epoch 89/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.6929 - accuracy: 0.4961\n",
      "Epoch 90/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.6923 - accuracy: 0.5002\n",
      "Epoch 91/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.6928 - accuracy: 0.4812\n",
      "Epoch 92/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.6929 - accuracy: 0.4837\n",
      "Epoch 93/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.6930 - accuracy: 0.4866\n",
      "Epoch 94/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.6931 - accuracy: 0.4982\n",
      "Epoch 95/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.6930 - accuracy: 0.4984\n",
      "Epoch 96/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.6928 - accuracy: 0.4869\n",
      "Epoch 97/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.6930 - accuracy: 0.4956\n",
      "Epoch 98/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.6925 - accuracy: 0.4788\n",
      "Epoch 99/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.6930 - accuracy: 0.4991\n",
      "Epoch 100/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.6929 - accuracy: 0.4956\n",
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_7 (Flatten)          (None, 38)                0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 1024)              39936     \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 128)               65664     \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 2)                 258       \n",
      "=================================================================\n",
      "Total params: 630,658\n",
      "Trainable params: 630,658\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(), \n",
    "                                    tf.keras.layers.Dense(1024, activation=tf.nn.relu), \n",
    "                                    tf.keras.layers.Dense(512, activation=tf.nn.relu), \n",
    "                                    tf.keras.layers.Dense(128, activation=tf.nn.relu), \n",
    "                                    tf.keras.layers.Dense(2, activation=tf.nn.softmax)])\n",
    "\n",
    "model.compile(optimizer = tf.optimizers.Adam(),\n",
    "              loss = 'sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, epochs=100)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.5007\n",
      "Test Accuracy:  0.5024\n"
     ]
    }
   ],
   "source": [
    "train_loss, train_accuracy = model.evaluate(X_train, y_train, verbose = False)\n",
    "print(\"Train Accuracy: {:.4f}\".format(train_accuracy))\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose = False)\n",
    "print(\"Test Accuracy:  {:.4f}\".format(test_accuracy))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arquitectura 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 324.1044 - accuracy: 0.6234\n",
      "Epoch 2/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 5.2441 - accuracy: 0.6394\n",
      "Epoch 3/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 2.2339 - accuracy: 0.6542\n",
      "Epoch 4/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.8907 - accuracy: 0.6492\n",
      "Epoch 5/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.7527 - accuracy: 0.6505\n",
      "Epoch 6/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.7635 - accuracy: 0.6617\n",
      "Epoch 7/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.5822 - accuracy: 0.6970\n",
      "Epoch 8/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.5553 - accuracy: 0.7105\n",
      "Epoch 9/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.5714 - accuracy: 0.7013\n",
      "Epoch 10/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.6068 - accuracy: 0.6510\n",
      "Epoch 11/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.6002 - accuracy: 0.6979\n",
      "Epoch 12/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.5966 - accuracy: 0.6929\n",
      "Epoch 13/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.6222 - accuracy: 0.6717\n",
      "Epoch 14/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.5879 - accuracy: 0.7015\n",
      "Epoch 15/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.5923 - accuracy: 0.6878\n",
      "Epoch 16/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.5834 - accuracy: 0.7000\n",
      "Epoch 17/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.5855 - accuracy: 0.6959\n",
      "Epoch 18/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.8343 - accuracy: 0.6417\n",
      "Epoch 19/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 1.6992 - accuracy: 0.5868\n",
      "Epoch 20/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.6458 - accuracy: 0.6506\n",
      "Epoch 21/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.6298 - accuracy: 0.6747\n",
      "Epoch 22/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.6245 - accuracy: 0.6790\n",
      "Epoch 23/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.6204 - accuracy: 0.6683\n",
      "Epoch 24/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.6576 - accuracy: 0.6655\n",
      "Epoch 25/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.6218 - accuracy: 0.6736\n",
      "Epoch 26/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.6392 - accuracy: 0.6686\n",
      "Epoch 27/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.7706 - accuracy: 0.5553\n",
      "Epoch 28/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.6916 - accuracy: 0.5259\n",
      "Epoch 29/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.9589 - accuracy: 0.4991\n",
      "Epoch 30/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.9262 - accuracy: 0.5024\n",
      "Epoch 31/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.6936 - accuracy: 0.4892\n",
      "Epoch 32/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.6930 - accuracy: 0.5108\n",
      "Epoch 33/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.6978 - accuracy: 0.5043\n",
      "Epoch 34/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 1.1751 - accuracy: 0.5157\n",
      "Epoch 35/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.7107 - accuracy: 0.5030\n",
      "Epoch 36/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.6945 - accuracy: 0.5164\n",
      "Epoch 37/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.6933 - accuracy: 0.4967\n",
      "Epoch 38/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.6932 - accuracy: 0.5064\n",
      "Epoch 39/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.6933 - accuracy: 0.4900\n",
      "Epoch 40/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.6933 - accuracy: 0.4948\n",
      "Epoch 41/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.6935 - accuracy: 0.4831\n",
      "Epoch 42/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.6934 - accuracy: 0.4933\n",
      "Epoch 43/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.6933 - accuracy: 0.4918\n",
      "Epoch 44/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.6933 - accuracy: 0.5082\n",
      "Epoch 45/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.6936 - accuracy: 0.4819\n",
      "Epoch 46/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.6933 - accuracy: 0.4947\n",
      "Epoch 47/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.6932 - accuracy: 0.5030\n",
      "Epoch 48/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.6934 - accuracy: 0.4946\n",
      "Epoch 49/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.6933 - accuracy: 0.5035\n",
      "Epoch 50/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.6934 - accuracy: 0.4946\n",
      "Epoch 51/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.6933 - accuracy: 0.5120\n",
      "Epoch 52/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.6934 - accuracy: 0.4811\n",
      "Epoch 53/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.6933 - accuracy: 0.4974\n",
      "Epoch 54/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.6934 - accuracy: 0.5011\n",
      "Epoch 55/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.6933 - accuracy: 0.4920\n",
      "Epoch 56/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.6933 - accuracy: 0.4936\n",
      "Epoch 57/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.6932 - accuracy: 0.5025\n",
      "Epoch 58/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.6933 - accuracy: 0.4917\n",
      "Epoch 59/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.6933 - accuracy: 0.4915\n",
      "Epoch 60/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.6932 - accuracy: 0.5054\n",
      "Epoch 61/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.6931 - accuracy: 0.5092: 0s - loss: 0\n",
      "Epoch 62/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.6931 - accuracy: 0.5065\n",
      "Epoch 63/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.6933 - accuracy: 0.4970\n",
      "Epoch 64/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.6931 - accuracy: 0.5046\n",
      "Epoch 65/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.6934 - accuracy: 0.4968\n",
      "Epoch 66/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.6933 - accuracy: 0.4987\n",
      "Epoch 67/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.6933 - accuracy: 0.4927\n",
      "Epoch 68/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.6933 - accuracy: 0.4984\n",
      "Epoch 69/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.6933 - accuracy: 0.4979\n",
      "Epoch 70/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.6933 - accuracy: 0.4973\n",
      "Epoch 71/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.6933 - accuracy: 0.4996\n",
      "Epoch 72/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.6936 - accuracy: 0.4766\n",
      "Epoch 73/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.6932 - accuracy: 0.5065\n",
      "Epoch 74/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.6932 - accuracy: 0.4954\n",
      "Epoch 75/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.6934 - accuracy: 0.4976\n",
      "Epoch 76/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.6932 - accuracy: 0.5063\n",
      "Epoch 77/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.6933 - accuracy: 0.5149\n",
      "Epoch 78/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.6934 - accuracy: 0.4875\n",
      "Epoch 79/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.6933 - accuracy: 0.4948\n",
      "Epoch 80/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "232/232 [==============================] - 1s 3ms/step - loss: 0.6932 - accuracy: 0.5060: 0s - loss: 0.6\n",
      "Epoch 81/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.6933 - accuracy: 0.4901\n",
      "Epoch 82/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.6933 - accuracy: 0.4988\n",
      "Epoch 83/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.6933 - accuracy: 0.4917\n",
      "Epoch 84/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.6933 - accuracy: 0.4848\n",
      "Epoch 85/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.6933 - accuracy: 0.4952\n",
      "Epoch 86/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.6933 - accuracy: 0.4874\n",
      "Epoch 87/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.6933 - accuracy: 0.4878\n",
      "Epoch 88/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.6932 - accuracy: 0.5073\n",
      "Epoch 89/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.6933 - accuracy: 0.4848\n",
      "Epoch 90/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.6932 - accuracy: 0.5098\n",
      "Epoch 91/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.6933 - accuracy: 0.4945\n",
      "Epoch 92/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.6932 - accuracy: 0.4967\n",
      "Epoch 93/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.6933 - accuracy: 0.4911\n",
      "Epoch 94/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.6932 - accuracy: 0.5044\n",
      "Epoch 95/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.6933 - accuracy: 0.4939\n",
      "Epoch 96/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.6932 - accuracy: 0.5021\n",
      "Epoch 97/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.6932 - accuracy: 0.4990\n",
      "Epoch 98/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.6932 - accuracy: 0.4991\n",
      "Epoch 99/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.6933 - accuracy: 0.4926\n",
      "Epoch 100/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.6933 - accuracy: 0.4893\n",
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_8 (Flatten)          (None, 38)                0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 128)               4992      \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 1024)              525312    \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 2)                 2050      \n",
      "=================================================================\n",
      "Total params: 598,402\n",
      "Trainable params: 598,402\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(), \n",
    "                                    tf.keras.layers.Dense(128, activation=tf.nn.relu), \n",
    "                                    tf.keras.layers.Dense(512, activation=tf.nn.relu), \n",
    "                                    tf.keras.layers.Dense(1024, activation=tf.nn.relu), \n",
    "                                    tf.keras.layers.Dense(2, activation=tf.nn.softmax)])\n",
    "\n",
    "model.compile(optimizer = tf.optimizers.Adam(),\n",
    "              loss = 'sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, epochs=100)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.5007\n",
      "Test Accuracy:  0.5024\n"
     ]
    }
   ],
   "source": [
    "train_loss, train_accuracy = model.evaluate(X_train, y_train, verbose = False)\n",
    "print(\"Train Accuracy: {:.4f}\".format(train_accuracy))\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose = False)\n",
    "print(\"Test Accuracy:  {:.4f}\".format(test_accuracy))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
